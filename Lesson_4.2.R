# –ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ tidymodels --------------------------
# 15 –º–∞—è 2025 –≥–æ–¥–∞
# –ï.–ù. –ú–∞—Ç–µ—Ä–æ–≤ –¥–ª—è –∫—É—Ä—Å–∞ ITMO –ë–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞
# –ü–ó 4.2
# —Ü–µ–ª—å –∑–∞–Ω—è—Ç–∏—è - –æ—Ç—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞–≤—ã–∫–∏ —Ä–∞–±–æ—Ç—ã —Å –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π {tidymodels}

# –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –Ω–µ—Ç—Ä–∏–≤–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è {tidymodels}
# –≤ —Ä–∞–±–æ—Ç–µ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ä—è–¥–∞–º–∏:
# https://naukaidannye.netlify.app/blog/posts/2021-02-19-modeltime/
# –≤ —Ä–∞–±–æ—Ç–µ —Å –≥–µ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏:
# https://geocompx.org/post/2025/sml-bp1/
# –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–æ–≤:
# Supervised Machine Learning for Text Analysis in R
# https://smltar.com/

# –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:
# 1. –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
# 2. –∑–∞–¥–∞—á–∏ —Ä–µ–≥–µ—Ä–µ—Å—Å–∏–∏
# ? –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏

# —É–ø—Ä–æ—Å—Ç–∏–º –ø—Ä–∏–º–µ—Ä –∏–∑:
# https://www.youtube.com/watch?v=J32pRt1nuoY&t=1262s&ab_channel=JamesWade
# https://jameshwade.quarto.pub/mlops-in-r-the-whole-game/
# https://jameshwade.com/posts/2022-12-27_mlops-the-whole-game.html

library(tidyverse)
library(tidymodels)
tidymodels_prefer()
library(magrittr)

library(palmerpenguins)
library(conflicted)
conflict_prefer("penguins", "palmerpenguins")

# 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ----------------------------------------------------

penguins_df <- penguins |>
  filter(!is.na(sex)) |>
  select(-year, -island)

penguins_df |>
  ggplot(aes(x = flipper_length_mm, 
             y = body_mass_g, 
             color = sex, size = bill_length_mm)) +
  geom_point(alpha = 0.4) +
  facet_wrap(~species) +
  theme_bw()

# 2. –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –≤—ã–±–æ—Ä–∫–∏ -------------------------------------------------

# –∑–∞–¥–∞–µ—Ç –Ω–∞—á–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª, 
# —á—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç —É–ª—É—á—à–∏—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å –∫–æ–¥–∞
set.seed(2025)

# —Ä–∞–∑–±–∏–µ–Ω–∏–µ
penguin_split <- initial_split(penguins_df, 
                               strata = sex,
                               prop = 0.8)

# –æ–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞
penguin_train <- training(penguin_split) %T>% print()

# —Ç–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞
penguin_test <- testing(penguin_split) %T>% print()

# <–û–±—É—á–∞—é—â–∞—è/–¢–µ—Å—Ç–æ–≤–∞—è/–í—Å—è>
penguin_split

# –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
penguin_folds <- vfold_cv(penguin_train) %T>% print()

# 3. –§–æ—Ä–º—É–ª–∞ --------------------------------------------------------------

# –ø—Ä–æ–ø—É—Å–∫–∞–µ–º, —Å–º. –¥–∞–ª–µ–µ

# 4. –ö–æ–Ω—Å—Ç—Ä—É–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ --------------------------------------------

penguin_rec <-
  recipe(sex ~ ., data = penguin_train) |>
  step_YeoJohnson(all_numeric_predictors()) |>
  step_normalize(all_numeric_predictors()) |>
  step_dummy(species)

penguin_rec

summary(penguin_rec)

# 5. –£–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ ------------------------------------------------------

glm_spec <-
  logistic_reg() |>
  set_engine("glm")

library(ranger)

tree_spec <-
  rand_forest(min_n = tune()) |>
  set_engine("ranger") |>
  set_mode("classification")

# 5. –†–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å (workflow) -------------------------------------------

# future! üöÄ - –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
library(future)
plan(sequential)

workflow_set <-
  workflow_set(
    preproc = list(penguin_rec),
    models = list(
      glm = glm_spec,
      tree = tree_spec)
  ) |>
  workflow_map(resamples = penguin_folds)

# 6. –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π ------------------------------------------------

rank_results(workflow_set,
             select_best = TRUE)

workflow_set |> autoplot() +
  theme_bw()

workflow_set |> autoplot(select_best = TRUE) +
  theme_bw()

# –≤—ã–±–æ—Ä –Ω–∞–∏–ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
best_model_id <- "recipe_tree" # –∏–∑ workflow_set

best_fit <-
  workflow_set |>
  extract_workflow_set_result(best_model_id) |>
  select_best(metric = "accuracy")

# —Ä–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞–∏–ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
final_workflow <-
  workflow_set |>
  extract_workflow(best_model_id) |>
  finalize_workflow(best_fit)

# 7. –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ----------------------------------------------------

# –¥–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
final_fit <-
  final_workflow |>
  last_fit(penguin_split)

# —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
collect_metrics(final_fit)

# –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ
# —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–∏–º –º–æ–¥–µ–ª—å –Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ
# –º–æ–¥–µ–ª—å –¥–ª—è –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
final_model <- fit(final_workflow, penguins_df)

# –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
new_penguin <- tribble(~species, 
                       ~bill_length_mm, 
                       ~bill_depth_mm, 
                       ~flipper_length_mm, 
                       ~body_mass_g,
                       "Adelie", 38.5, 19.4, 185, 3700)

# –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
predict(final_model, new_data = new_penguin)

# 8. –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏ ---------------------------------------------------

final_fit |>
  collect_predictions() |>
  roc_curve(truth = sex, 
            .pred_female) |>
  autoplot()

# –º–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫

conf_matrix <- 
  collect_predictions(final_fit) |>
  conf_mat(sex, .pred_class)

# —Ç–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞
model_heatmap <- 
  conf_matrix |>
  autoplot(type = "heatmap")

# –º–æ–∑–∞–∏—á–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫
model_mosaic <-
  conf_matrix |>
  autoplot(type = "mosaic")

library(patchwork)

model_heatmap + model_mosaic

###############################
# —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º —á–∏—Å–ª–æ–≤–æ–π –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä
# –∑–∞–¥–∞—á–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
###############################

# –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
library(tidymodels)
library(tidyverse)
tidymodels_prefer()

# –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ---------------------------------------------------------

our_data <- diamonds |>
  na.omit() |>
  select(price, carat, depth, table, x, y, z, color, cut)

our_data |>
  ggplot(aes(x = carat, y = price)) + geom_point(alpha = 0.2)

# —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –≤—ã–±–æ—Ä–∫–∏ ----------------------------------------------------

set.seed(2025)

splits <- initial_split(our_data, prop = 0.8)

diamonds_train <- training(splits)
diamonds_test <- testing(splits)

diamonds_folds <- vfold_cv(diamonds_train)

# –º–æ–¥–µ–ª—å ------------------------------------------------------------------

# 1-—è –º–æ–¥–µ–ª—å: random forest
rf_reg_spec <- 
  rand_forest(trees = 200, 
              min_n = 5) |>
  set_mode("regression") |>
  set_engine("ranger", 
             # –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø–æ—Ç–æ–º –º–æ–∂–Ω–æ –±—ã–ª–æ –≤—ã—è–≤–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
             importance = "impurity")
rf_reg_spec

# 2-—è –º–æ–¥–µ–ª—å: –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è

lin_reg_spec <- linear_reg()

# –ø—Ä–µ–¥—Å–∫–∞–∂–µ–º —Ü–µ–Ω—ã –Ω–∞ –∞–ª–º–∞–∑—ã -----------------------------------------------

rf_reg_fit <- rf_reg_spec |> 
  fit(price ~ ., data = diamonds_train)
rf_reg_fit

lr_reg_fit <- lin_reg_spec |> 
  fit(price ~ ., data = diamonds_train)
lr_reg_fit |> tidy()

# –ø—Ä–æ–≤–µ—Ä–∏–º –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è

predict(rf_reg_fit, new_data = diamonds_test)

augment(rf_reg_fit, new_data = diamonds_test) |>
  select(price, .pred) |>
  ggplot(aes(x = price, y = .pred)) + 
  geom_point(alpha = 0.1) +
  geom_smooth(se = FALSE, method = "lm")

augment(lr_reg_fit, new_data = diamonds_test) |>
  select(price, .pred) |>
  ggplot(aes(x = price, y = .pred)) + 
  geom_point(alpha = 0.1) +
  geom_smooth(se = FALSE, method = "lm")

# —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø–æ–¥—Ö–æ–¥ {tidymodels} ------------------------------------------

# —Ñ–æ—Ä–º—É–ª–∞ + "—Ä–µ—Ü–µ–ø—Ç"
our_recipe <- recipe(price ~ .,
                     data = our_data) |>
  # –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —É–¥–∞–ª–∏—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è 
  # –∫—Ä–∞–π–Ω–µ —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã–º–∏ –∏ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏
  step_nzv(all_predictors()) |> 
  # —É–¥–∞–ª–∏—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, –∏–º–µ—é—â–∏–µ –±–æ–ª—å—à—É—é –∞–±—Å–æ–ª—é—Ç–Ω—É—é –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é —Å –¥—Ä—É–≥–∏–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏
  step_corr(all_numeric_predictors()) |>
  # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–∞–∫, —á—Ç–æ–±—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ 
  # –±—ã–ª–æ —Ä–∞–≤–Ω–æ –µ–¥–∏–Ω–∏—Ü–µ, –∞ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ ‚Äî –Ω—É–ª—é
  step_normalize(all_numeric_predictors()) 

workflow_set <-
  workflow_set(
    preproc = list(our_recipe),
    models = list(
      rand_for = rf_reg_spec,
      lin_reg = lin_reg_spec)
  ) |>
  workflow_map(resamples = diamonds_folds,
               metrics = metric_set(rmse, mae, rsq))

# –≤—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å

rank_results(workflow_set,
             select_best = TRUE)

best_model_id <- "recipe_rand_for"

workflow_set |> autoplot() +
  theme_bw()

# –¥–æ–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å

best_fit <-
  workflow_set |>
  extract_workflow_set_result(best_model_id) |>
  select_best(metric = "rmse")

final_workflow <-
  workflow_set |>
  extract_workflow(best_model_id) |>
  finalize_workflow(best_fit)

final_fit <-
  final_workflow |>
  last_fit(splits)

collect_metrics(final_fit)

final_model <- fit(final_workflow, our_data)

# summary(final_model)

# –≤–∏–∑—É–∞–ª—å–Ω–æ —Å—Ä–∞–≤–Ω–∏–º –∫–∞—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏

augment(final_model, new_data = diamonds_test) |>
  select(price, .pred) |>
  ggplot(aes(x = price, y = .pred)) + 
  geom_point(alpha = 0.1) +
  geom_smooth(se = FALSE, method = "lm")

# –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–æ–≤ –≤ –º–æ–¥–µ–ª–∏ -------------------------------------------

library(vip)

final_fit |>
  extract_fit_parsnip() |>
  vip(num_features = 5)
